{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e0b615d-4b07-48a1-9f97-3ad96e733eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2345d6ed-ba14-4b29-9ac6-022a70a2e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression:\n",
    "    def __init__(self):\n",
    "        self.x=None                                          \n",
    "        self.y=None\n",
    "        self.c=None                                        #regulirization rate                                   \n",
    "        self.epochs=None                                   #epochs\n",
    "        self.lr_rate=None                                  #learning rate\n",
    "        self.w=None                                        #weights\n",
    "        self.b=None                                        #bias\n",
    "        self.loss_per_epoch=None                           #each epoch loss\n",
    "        \n",
    "        \n",
    "\n",
    "    def fit(self,x,y,lr_rate=0.01,c=0.01,epochs=3):\n",
    "        \"\"\"\n",
    "        X: data matrix with (rows,columns) or (points,features)\n",
    "        \n",
    "        y: class numbers in intergeer example [1,2,0,1,2,0,2,1]\n",
    "        \n",
    "        lr_rate: learning rate\n",
    "        \n",
    "        C: regulization constant\n",
    "        \n",
    "        epochs: number of epochs\n",
    "        \n",
    "        \"\"\"\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        self.lr_rate=lr_rate\n",
    "        self.c=c\n",
    "        self.w=np.random.normal(0,1,len(x[0]))              #initilizing weights\n",
    "        self.b=0                                            #initilizing bias\n",
    "        self.epochs=epochs \n",
    "        self.SGD()                                          #calling SGD\n",
    "        \n",
    "        \n",
    "    def mse_loss(self,actual,predicted):\n",
    "        \n",
    "        \"\"\"\n",
    "        actual : true values (must be a 1D vector) \n",
    "        \n",
    "        predicted : predicted values (must be a 1D vector)\n",
    "        \n",
    "        \"\"\"\n",
    "        return np.mean((actual-predicted)**2)          #return mse \n",
    "    \n",
    "    \n",
    "    \n",
    "    def weights_update(self,actual,predicted,x):\n",
    "        \"\"\"\n",
    "        actual : true values (must be a 1D vector) \n",
    "        \n",
    "        predicted : predicted values (must be a 1D vector)\n",
    "        \n",
    "        \n",
    "        L=(1/n)(y-y^)**2\n",
    "        \n",
    "        dL/dw=-(1/n)*2*(y-y^)*x          hear dL/dw , x , w are vectors  \n",
    "        \n",
    "        -2*(actual-predicted)             ----> 1D vector \n",
    "        \n",
    "        np.matric(-2*(actual-predicted))  ----> 2D matrix  example shape (1,number_of_points)\n",
    "        \n",
    "        np.matrix(x)                      ----> 2D matrix example shape (number_of_points,number_of_features)\n",
    "        \n",
    "        \n",
    "        np.matrix(-2*(actual-predicted)) *  np.matrix(x) -------> (1,number_of_points) * (number_of_points,number_of_features) ----> (1,number_of_features)\n",
    "    \n",
    "        1/n for average\n",
    "        \n",
    "        \n",
    "        flatten ---> to convert result into 1D vector\n",
    "        \n",
    "        \"\"\"\n",
    "        return np.array((1/len(actual))*(np.matrix(-2*(actual-predicted))*np.matrix(x))).flatten() + self.c * 2*self.w\n",
    "    \n",
    "    \n",
    "    \n",
    "    def bias_update(self,actual,predicted):\n",
    "        \n",
    "        \"\"\"\n",
    "        actual : true values (must be a 1D vector) \n",
    "        \n",
    "        predicted : predicted values (must be a 1D vector)\n",
    "        \n",
    "        L=(1/n)(y-y^)**2\n",
    "        \n",
    "        dL/db = -(1/n)*2*(y-y^)   hear dL/db is scalar\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        return np.mean(-2*(actual-predicted))\n",
    "    \n",
    "    \n",
    "    def predict(self,x):\n",
    "        \"\"\"\n",
    "         x ; data matrix with (rows,columns) or (points,features)\n",
    "         \n",
    "         np.matrix(x)      -----> matrix with (points,features)\n",
    "         \n",
    "         np.matrix(self.w)   ------> matrix with (1,features)\n",
    "         \n",
    "         np.matrix(x)*np.matrix(self.w).T+self.b  ----->  (points,features) * (features,1) -----> (points,1)\n",
    "         \n",
    "         add bias \n",
    "         \n",
    "         each point get a output  \n",
    "         \n",
    "         flattern ------> change output to 1D vector (1,points)\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.array(np.matrix(x)*np.matrix(self.w).T+self.b).flatten()\n",
    "    \n",
    "    \n",
    "    def SGD(self):\n",
    "        loss_per_epoch=[]                                                #loss for each epoch\n",
    "        for i in range(self.epochs):                  \n",
    "            predicted=self.predict(self.x)                               #model predictions\n",
    "            loss_per_epoch.append(self.mse_loss(self.y,predicted))       #loss for predictions\n",
    "            grad_w=self.weights_update(self.y,predicted,x)               #grad_w for w's\n",
    "            grad_b=self.bias_update(self.y,predicted)                    #grad_b for b\n",
    "            self.w=self.w-self.lr_rate*grad_w                            #w_new = w_old- learn_rate* grad_w\n",
    "            self.b=self.b-self.lr_rate*grad_b \n",
    "        self.loss_per_epoch=loss_per_epoch          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "959f29b1-fa71-4312-a819-af17d1bffef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cf0d21b-3d65-48ad-b57a-5fcb02281d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=make_regression(n_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a4edd58-475b-4032-9f91-ecbb7b31b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=linear_regression()\n",
    "lr.fit(x,y,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35e3eb07-776d-415b-875b-8267aa745837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147.2501015653003"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.loss_per_epoch[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89dc1124-f826-4c31-b20e-8d7b613a7c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([121.43104775])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6e58836-7db3-45c4-a2e8-e423db8cdeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123.16951373974985"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f22c4f20-1b47-466a-b6d6-6dfb1848c10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331.3472592998655"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e130a3d-fbd5-4023-a00e-cd71fa97bcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyterlab] *",
   "language": "python",
   "name": "conda-env-jupyterlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
